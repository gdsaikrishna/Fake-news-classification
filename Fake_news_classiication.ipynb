{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#imports block\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "#nltk.download()\n",
    "from nltk import word_tokenize, pos_tag\n",
    "#importing the Stemming function from nltk library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Input\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>31-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>31-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>30-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>29-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>25-Dec-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject       date  \n",
       "0  Donald Trump just couldn t wish all Americans ...    News  31-Dec-17  \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News  31-Dec-17  \n",
       "2  On Friday, it was revealed that former Milwauk...    News  30-Dec-17  \n",
       "3  On Christmas day, Donald Trump announced that ...    News  29-Dec-17  \n",
       "4  Pope Francis used his annual Christmas Day mes...    News  25-Dec-17  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last week, the mostly female audience of  The ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan Governor Rick Snyder was thirsty to p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONESSEN, Pennsylvania/WASHINGTON (Reuters) - ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nothing says Hollywood like supporting a seria...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK (Reuters) - President-elect Donald Tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44935</th>\n",
       "      <td>MOSCOW (Reuters) - Russia has demanded an emer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44936</th>\n",
       "      <td>WASHINGTON (Reuters) - Japan views U.S. Presid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44937</th>\n",
       "      <td>UNITED NATIONS (Reuters) - United Nations Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44938</th>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. Senate on Thur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44939</th>\n",
       "      <td>I think we are in a real moment like Nixon ??...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  class\n",
       "0      Last week, the mostly female audience of  The ...      0\n",
       "1      Michigan Governor Rick Snyder was thirsty to p...      0\n",
       "2      MONESSEN, Pennsylvania/WASHINGTON (Reuters) - ...      1\n",
       "3      Nothing says Hollywood like supporting a seria...      0\n",
       "4      NEW YORK (Reuters) - President-elect Donald Tr...      1\n",
       "...                                                  ...    ...\n",
       "44935  MOSCOW (Reuters) - Russia has demanded an emer...      1\n",
       "44936  WASHINGTON (Reuters) - Japan views U.S. Presid...      1\n",
       "44937  UNITED NATIONS (Reuters) - United Nations Secr...      1\n",
       "44938  WASHINGTON (Reuters) - The U.S. Senate on Thur...      1\n",
       "44939   I think we are in a real moment like Nixon ??...      0\n",
       "\n",
       "[44940 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df['class'] = 0\n",
    "true_df['class'] = 1\n",
    "#Concat Full Data\n",
    "df = pd.concat([fake_df, true_df])\n",
    "#Shuffle the Data\n",
    "df = df.sample(frac = 1)\n",
    "df.reset_index(inplace = True)\n",
    "#Filter Required columns\n",
    "df= df[['text','class']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "#Text Processing pipeline: Lower case + remove punctuation + Tokenization + Lemmatization + Stop words Removal\n",
    "#Convert these to Vectors using BOW or TF-IDF or Embeddings(Glove, fasttext, Word2Vec)\n",
    "#Make Baseline ML models(Log Reg, SVM, Naive Bayes, Decision Trees, RF, XGBoost Classifier)\n",
    "#Hyperparameter Tuning of above models\n",
    "#Make DL models using CNN, LSTM's, BERT/RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    #remove http links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    #expanding some words\n",
    "    text = decontracted(text)\n",
    "    #remove special character\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation Required??? \n",
    "\n",
    "Normalisation performs:\n",
    "\n",
    "    Converting dates to text\n",
    "    Numbers to text\n",
    "    Currency/Percent signs to text\n",
    "    Expanding of abbreviations (content dependent) NLP - Natural Language Processing, Neuro-linguistic programming, Non-Linear programming\n",
    "    Spelling mistakes correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from normalise.normalisation import normalise\n",
    "\n",
    "#def normalization(tokens):\n",
    "#    user_abbr = { 'NLP' : 'Natural Language Processing'}\n",
    "#    normalised_tokens = normalise(tokens, user_abbrevs = user_abbr, verbose = False)\n",
    "#    return normalised_tokens\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "def stemming(words):\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text_processed = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_processed\n",
    "\n",
    "\n",
    "#Lower text: text = text.lower()\n",
    "#Tokenization Code:  words = word_tokenize(text)\n",
    "#Parts Of Speech Tagging: words = pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.vocab.Vocab' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DKRISH~1.GUN\\AppData\\Local\\Temp/ipykernel_11452/606304830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msai\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sai\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.vocab.Vocab' object is not callable"
     ]
    }
   ],
   "source": [
    "sai = nlp.vocab(\"sai\")\n",
    "print(sai.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n",
      "****************************************************************************************************\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that Instead he had to give a shout out to his enemies haters and the very dishonest fake news media The former reality show star had just one job to do and he couldn t do it As our Country rapidly grows stronger and smarter I want to wish all of my friends supporters enemies haters and even the very dishonest Fake News Media a Happy and Healthy New Year President Angry Pants tweeted 2018 will be a great year for America As our Country rapidly grows stronger and smarter I want to wish all of my friends supporters enemies haters and even the very dishonest Fake News Media a Happy and Healthy New Year 2018 will be a great year for America Donald J Trump realDonaldTrump December 31 2017Trump s tweet went down about as welll as you d expect What kind of president sends a New Year s greeting like this despicable petty infantile gibberish Only Trump His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year Bishop Talbert Swan TalbertSwan December 31 2017no one likes you Calvin calvinstowell December 31 2017Your impeachment would make 2018 a great year for America but I ll also accept regaining control of Congress Miranda Yaver mirandayaver December 31 2017Do you hear yourself talk When you have to include that many people that hate you you have to wonder Why do the they all hate me Alan Sandoval AlanSandoval13 December 31 2017Who uses the word Haters in a New Years wish Marlene marlene399 December 31 2017You can t just say happy new year Koren pollitt Korencarpenter December 31 2017Here s Trump s New Year s Eve tweet from 2016 Happy New Year to all including to my many enemies and those who have fought me and lost so badly they just don t know what to do Love Donald J Trump realDonaldTrump December 31 2016This is nothing new for Trump He s been doing this for years Trump has directed messages to his enemies and haters for New Year s Easter Thanksgiving and the anniversary of 9 11 pic twitter com 4FPAe2KypA Daniel Dale ddale8 December 31 2017Trump s holiday tweets are clearly not presidential How long did he work at Hallmark before becoming President Steven Goodine SGoodine December 31 2017He s always been like this the only difference is that in the last few years his filter has been breaking down Roy Schulze thbthttt December 31 2017Who apart from a teenager uses the term haters Wendy WendyWhistles December 31 2017he s a fucking 5 year old Who Knows rainyday80 December 31 2017So to all the people who voted for this a hole thinking he would change once he got into power you were wrong 70 year old men don t change and now he s a year older Photo by Andrew Burton Getty Images\n",
      "Tokenize+Lemmatize:\n",
      "['Donald', 'Trump', 'just', 'couldn', 't', 'wish', 'all', 'Americans', 'a', 'Happy', 'New', 'Year', 'and', 'leave', 'it', 'at', 'that', 'instead', 'he', 'have', 'to', 'give', 'a', 'shout', 'out', 'to', 'his', 'enemy', 'hater', 'and', 'the', 'very', 'dishonest', 'fake', 'news', 'medium', 'the', 'former', 'reality', 'show', 'star', 'have', 'just', 'one', 'job', 'to', 'do', 'and', 'he', 'couldn', 't', 'do', 'it', 'as', 'our', 'Country', 'rapidly', 'grow', 'strong', 'and', 'smart', 'I', 'want', 'to', 'wish', 'all', 'of', 'my', 'friend', 'supporter', 'enemy', 'hater', 'and', 'even', 'the', 'very', 'dishonest', 'Fake', 'News', 'media', 'a', 'happy', 'and', 'Healthy', 'New', 'Year', 'President', 'Angry', 'Pants', 'tweet', '2018', 'will', 'be', 'a', 'great', 'year', 'for', 'America', 'as', 'our', 'Country', 'rapidly', 'grow', 'strong', 'and', 'smart', 'I', 'want', 'to', 'wish', 'all', 'of', 'my', 'friend', 'supporter', 'enemy', 'hater', 'and', 'even', 'the', 'very', 'dishonest', 'Fake', 'News', 'media', 'a', 'happy', 'and', 'Healthy', 'New', 'Year', '2018', 'will', 'be', 'a', 'great', 'year', 'for', 'America', 'Donald', 'J', 'Trump', 'realDonaldTrump', 'December', '31', '2017trump', 's', 'tweet', 'go', 'down', 'about', 'as', 'welll', 'as', 'you', 'd', 'expect', 'what', 'kind', 'of', 'president', 'send', 'a', 'New', 'Year', 's', 'greet', 'like', 'this', 'despicable', 'petty', 'infantile', 'gibberish', 'only', 'Trump', 'his', 'lack', 'of', 'decency', 'win', 't', 'even', 'allow', 'he', 'to', 'rise', 'above', 'the', 'gutter', 'long', 'enough', 'to', 'wish', 'the', 'american', 'citizen', 'a', 'happy', 'new', 'year', 'Bishop', 'Talbert', 'Swan', 'TalbertSwan', 'December', '31', '2017no', 'one', 'like', 'you', 'Calvin', 'calvinstowell', 'December', '31', '2017your', 'impeachment', 'would', 'make', '2018', 'a', 'great', 'year', 'for', 'America', 'but', 'I', 'll', 'also', 'accept', 'regain', 'control', 'of', 'Congress', 'Miranda', 'Yaver', 'mirandayaver', 'December', '31', '2017do', 'you', 'hear', 'yourself', 'talk', 'when', 'you', 'have', 'to', 'include', 'that', 'many', 'people', 'that', 'hate', 'you', 'you', 'have', 'to', 'wonder', 'why', 'do', 'the', 'you', 'all', 'hate', 'I', 'Alan', 'Sandoval', 'AlanSandoval13', 'December', '31', '2017who', 'use', 'the', 'word', 'Haters', 'in', 'a', 'New', 'Years', 'wish', 'Marlene', 'marlene399', 'December', '31', '2017you', 'can', 't', 'just', 'say', 'happy', 'new', 'year', 'Koren', 'pollitt', 'Korencarpenter', 'December', '31', '2017here', 's', 'Trump', 's', 'New', 'Year', 's', 'Eve', 'tweet', 'from', '2016', 'Happy', 'New', 'Year', 'to', 'all', 'include', 'to', 'my', 'many', 'enemy', 'and', 'those', 'who', 'have', 'fight', 'I', 'and', 'lose', 'so', 'badly', 'they', 'just', 'don', 't', 'know', 'what', 'to', 'do', 'love', 'Donald', 'J', 'Trump', 'realDonaldTrump', 'December', '31', '2016this', 'be', 'nothing', 'new', 'for', 'Trump', 'He', 's', 'be', 'do', 'this', 'for', 'year', 'Trump', 'have', 'direct', 'message', 'to', 'his', 'enemy', 'and', 'hater', 'for', 'New', 'Year', 's', 'Easter', 'Thanksgiving', 'and', 'the', 'anniversary', 'of', '9', '11', 'pic', 'twitter', 'com', '4fpae2kypa', 'Daniel', 'Dale', 'ddale8', 'December', '31', '2017trump', 's', 'holiday', 'tweet', 'be', 'clearly', 'not', 'presidential', 'how', 'long', 'do', 'he', 'work', 'at', 'Hallmark', 'before', 'become', 'President', 'Steven', 'Goodine', 'SGoodine', 'December', '31', '2017he', 's', 'always', 'be', 'like', 'this', 'the', 'only', 'difference', 'be', 'that', 'in', 'the', 'last', 'few', 'year', 'his', 'filter', 'have', 'be', 'break', 'down', 'Roy', 'Schulze', 'thbthttt', 'December', '31', '2017who', 'apart', 'from', 'a', 'teenager', 'use', 'the', 'term', 'hater', 'Wendy', 'WendyWhistles', 'December', '31', '2017he', 's', 'a', 'fucking', '5', 'year', 'old', 'who', 'know', 'rainyday80', 'December', '31', '2017so', 'to', 'all', 'the', 'people', 'who', 'vote', 'for', 'this', 'a', 'hole', 'thinking', 'he', 'would', 'change', 'once', 'he', 'get', 'into', 'power', 'you', 'be', 'wrong', '70', 'year', 'old', 'man', 'don', 't', 'change', 'and', 'now', 'he', 's', 'a', 'year', 'old', 'Photo', 'by', 'Andrew', 'Burton', 'Getty', 'Images']\n",
      " \n",
      "Remove stopword & punctuation: \n",
      "['Donald', 'Trump', 'couldn', 't', 'wish', 'Americans', 'Happy', 'New', 'Year', 'leave', 'instead', 'shout', 'enemy', 'hater', 'dishonest', 'fake', 'news', 'medium', 'reality', 'star', 'job', 'couldn', 't', 'Country', 'rapidly', 'grow', 'strong', 'smart', 'want', 'wish', 'friend', 'supporter', 'enemy', 'hater', 'dishonest', 'Fake', 'News', 'media', 'happy', 'Healthy', 'New', 'Year', 'President', 'Angry', 'Pants', 'tweet', '2018', 'great', 'year', 'America', 'Country', 'rapidly', 'grow', 'strong', 'smart', 'want', 'wish', 'friend', 'supporter', 'enemy', 'hater', 'dishonest', 'Fake', 'News', 'media', 'happy', 'Healthy', 'New', 'Year', '2018', 'great', 'year', 'America', 'Donald', 'J', 'Trump', 'realDonaldTrump', 'December', '31', '2017trump', 's', 'tweet', 'welll', 'd', 'expect', 'kind', 'president', 'send', 'New', 'Year', 's', 'greet', 'like', 'despicable', 'petty', 'infantile', 'gibberish', 'Trump', 'lack', 'decency', 'win', 't', 'allow', 'rise', 'gutter', 'long', 'wish', 'american', 'citizen', 'happy', 'new', 'year', 'Bishop', 'Talbert', 'Swan', 'TalbertSwan', 'December', '31', '2017no', 'like', 'Calvin', 'calvinstowell', 'December', '31', '2017your', 'impeachment', '2018', 'great', 'year', 'America', 'll', 'accept', 'regain', 'control', 'Congress', 'Miranda', 'Yaver', 'mirandayaver', 'December', '31', '2017do', 'hear', 'talk', 'include', 'people', 'hate', 'wonder', 'hate', 'Alan', 'Sandoval', 'AlanSandoval13', 'December', '31', '2017who', 'use', 'word', 'Haters', 'New', 'Years', 'wish', 'Marlene', 'marlene399', 'December', '31', '2017you', 't', 'happy', 'new', 'year', 'Koren', 'pollitt', 'Korencarpenter', 'December', '31', '2017here', 's', 'Trump', 's', 'New', 'Year', 's', 'Eve', 'tweet', '2016', 'Happy', 'New', 'Year', 'include', 'enemy', 'fight', 'lose', 'badly', 'don', 't', 'know', 'love', 'Donald', 'J', 'Trump', 'realDonaldTrump', 'December', '31', '2016this', 'new', 'Trump', 's', 'year', 'Trump', 'direct', 'message', 'enemy', 'hater', 'New', 'Year', 's', 'Easter', 'Thanksgiving', 'anniversary', '9', '11', 'pic', 'twitter', 'com', '4fpae2kypa', 'Daniel', 'Dale', 'ddale8', 'December', '31', '2017trump', 's', 'holiday', 'tweet', 'clearly', 'presidential', 'long', 'work', 'Hallmark', 'President', 'Steven', 'Goodine', 'SGoodine', 'December', '31', '2017he', 's', 'like', 'difference', 'year', 'filter', 'break', 'Roy', 'Schulze', 'thbthttt', 'December', '31', '2017who', 'apart', 'teenager', 'use', 'term', 'hater', 'Wendy', 'WendyWhistles', 'December', '31', '2017he', 's', 'fucking', '5', 'year', 'old', 'know', 'rainyday80', 'December', '31', '2017so', 'people', 'vote', 'hole', 'thinking', 'change', 'power', 'wrong', '70', 'year', 'old', 'man', 'don', 't', 'change', 's', 'year', 'old', 'Photo', 'Andrew', 'Burton', 'Getty', 'Images']\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\",'no','nor','not'])\n",
    "\n",
    "def spacy_process(text):\n",
    "    print(text)\n",
    "    print(100*'*')\n",
    "    text = clean_text(text)\n",
    "    print(text)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #Tokenization and lemmatization are done with the spacy nlp pipeline commands\n",
    "    lemma_list = []\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    print(\"Tokenize+Lemmatize:\")\n",
    "    print(lemma_list)\n",
    "    \n",
    "    #Filter the stopword\n",
    "    filtered_sentence =[] \n",
    "    for word in lemma_list:\n",
    "        if word not in custom_stopwords:\n",
    "            filtered_sentence.append(word)\n",
    "        #lexeme = nlp.vocab[word]\n",
    "        #if not lexeme.is_stop:\n",
    "        #    filtered_sentence.append(word) \n",
    "    \n",
    "    #Remove punctuation\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in filtered_sentence:\n",
    "        if word in punctuations:\n",
    "            filtered_sentence.remove(word)\n",
    "    print(\" \")\n",
    "    print(\"Remove stopword & punctuation: \")\n",
    "    print(filtered_sentence)\n",
    "\n",
    "first_row = fake_df.iloc[0]\n",
    "spacy_process(first_row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edaef9d03e0964944a4ac8a8046f0ca7775b12f92df181532561f3229a0e765e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
