{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#imports block\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "#nltk.download()\n",
    "from nltk import word_tokenize, pos_tag\n",
    "#importing the Stemming function from nltk library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Input\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>31-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>31-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>30-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>29-Dec-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>25-Dec-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject       date  \n",
       "0  Donald Trump just couldn t wish all Americans ...    News  31-Dec-17  \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News  31-Dec-17  \n",
       "2  On Friday, it was revealed that former Milwauk...    News  30-Dec-17  \n",
       "3  On Christmas day, Donald Trump announced that ...    News  29-Dec-17  \n",
       "4  Pope Francis used his annual Christmas Day mes...    News  25-Dec-17  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KABUL (Reuters) - A senior U.S. commander in A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON (Reuters) - Two U.S. Senators urged...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump is still beating his  widespread voter f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The bashing of Donald Trump is getting so old ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You know the age-old political trope that poli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44935</th>\n",
       "      <td>A teenage girl who fought back when she was al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44936</th>\n",
       "      <td>PHOENIX (Reuters) - Two National Football Leag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44937</th>\n",
       "      <td>LONDON (Reuters) - Prime Minister Theresa May ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44938</th>\n",
       "      <td>WASHINGTON (Reuters) - While he has swallowed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44939</th>\n",
       "      <td>The Center For Medical Progress warned us thes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  class\n",
       "0      KABUL (Reuters) - A senior U.S. commander in A...      1\n",
       "1      WASHINGTON (Reuters) - Two U.S. Senators urged...      1\n",
       "2      Trump is still beating his  widespread voter f...      0\n",
       "3      The bashing of Donald Trump is getting so old ...      0\n",
       "4      You know the age-old political trope that poli...      0\n",
       "...                                                  ...    ...\n",
       "44935  A teenage girl who fought back when she was al...      0\n",
       "44936  PHOENIX (Reuters) - Two National Football Leag...      1\n",
       "44937  LONDON (Reuters) - Prime Minister Theresa May ...      1\n",
       "44938  WASHINGTON (Reuters) - While he has swallowed ...      1\n",
       "44939  The Center For Medical Progress warned us thes...      0\n",
       "\n",
       "[44940 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df['class'] = 0\n",
    "true_df['class'] = 1\n",
    "#Concat Full Data\n",
    "df = pd.concat([fake_df, true_df])\n",
    "#Shuffle the Data\n",
    "df = df.sample(frac = 1)\n",
    "df.reset_index(inplace = True)\n",
    "#Filter Required columns\n",
    "df= df[['text','class']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "#Text Processing pipeline: Lower case + remove punctuation + Tokenization + Lemmatization + Stop words Removal\n",
    "#Convert these to Vectors using BOW or TF-IDF or Embeddings(Glove, fasttext, Word2Vec)\n",
    "#Make Baseline ML models(Log Reg, SVM, Naive Bayes, Decision Trees, RF, XGBoost Classifier)\n",
    "#Hyperparameter Tuning of above models\n",
    "#Make DL models using CNN, LSTM's, BERT/RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    #lower case text\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    #remove http links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    #expanding some words\n",
    "    text = decontracted(text)\n",
    "    #remove special character\n",
    "    #text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    #remove numbers\n",
    "    #text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
    "    \n",
    "    #text = text.strip()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation Required??? \n",
    "\n",
    "Normalisation performs:\n",
    "\n",
    "    Converting dates to text\n",
    "    Numbers to text\n",
    "    Currency/Percent signs to text\n",
    "    Expanding of abbreviations (content dependent) NLP - Natural Language Processing, Neuro-linguistic programming, Non-Linear programming\n",
    "    Spelling mistakes correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from normalise.normalisation import normalise\n",
    "\n",
    "#def normalization(tokens):\n",
    "#    user_abbr = { 'NLP' : 'Natural Language Processing'}\n",
    "#    normalised_tokens = normalise(tokens, user_abbrevs = user_abbr, verbose = False)\n",
    "#    return normalised_tokens\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "def stemming(words):\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text_processed = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_processed\n",
    "\n",
    "\n",
    "#Lower text: text = text.lower()\n",
    "#Tokenization Code:  words = word_tokenize(text)\n",
    "#Parts Of Speech Tagging: words = pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n",
      "****************************************************************************************************\n",
      "Tokenize+Lemmatize:\n",
      "['donald', 'trump', 'just', 'couldn', 't', 'wish', 'all', 'americans', 'a', 'happy', 'new', 'year', 'and', 'leave', 'it', 'at', 'that', 'instead', 'he', 'have', 'to', 'give', 'a', 'shout', 'out', 'to', 'his', 'enemy', 'hater', 'and', 'the', 'very', 'dishonest', 'fake', 'news', 'medium', 'the', 'former', 'reality', 'show', 'star', 'have', 'just', 'one', 'job', 'to', 'do', 'and', 'he', 'couldn', 't', 'do', 'it', 'as', 'our', 'country', 'rapidly', 'grow', 'strong', 'and', 'smart', 'I', 'want', 'to', 'wish', 'all', 'of', 'my', 'friend', 'supporter', 'enemy', 'hater', 'and', 'even', 'the', 'very', 'dishonest', 'fake', 'news', 'medium', 'a', 'happy', 'and', 'healthy', 'new', 'year', 'president', 'angry', 'pant', 'tweet', 'will', 'be', 'a', 'great', 'year', 'for', 'america', 'as', 'our', 'country', 'rapidly', 'grow', 'strong', 'and', 'smart', 'I', 'want', 'to', 'wish', 'all', 'of', 'my', 'friend', 'supporter', 'enemy', 'hater', 'and', 'even', 'the', 'very', 'dishonest', 'fake', 'news', 'medium', 'a', 'happy', 'and', 'healthy', 'new', 'year', 'will', 'be', 'a', 'great', 'year', 'for', 'america', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'trump', 's', 'tweet', 'go', 'down', 'about', 'as', 'welll', 'as', 'you', 'd', 'expect', 'what', 'kind', 'of', 'president', 'send', 'a', 'new', 'year', 's', 'greeting', 'like', 'this', 'despicable', 'petty', 'infantile', 'gibberish', 'only', 'trump', 'his', 'lack', 'of', 'decency', 'win', 't', 'even', 'allow', 'he', 'to', 'rise', 'above', 'the', 'gutter', 'long', 'enough', 'to', 'wish', 'the', 'american', 'citizen', 'a', 'happy', 'new', 'year', 'bishop', 'talbert', 'swan', 'talbertswan', 'december', 'no', 'one', 'like', 'you', 'calvin', 'calvinstowell', 'december', 'your', 'impeachment', 'would', 'make', 'a', 'great', 'year', 'for', 'america', 'but', 'I', 'll', 'also', 'accept', 'regain', 'control', 'of', 'congress', 'miranda', 'yaver', 'mirandayaver', 'december', 'do', 'you', 'hear', 'yourself', 'talk', 'when', 'you', 'have', 'to', 'include', 'that', 'many', 'people', 'that', 'hate', 'you', 'you', 'have', 'to', 'wonder', 'why', 'do', 'the', 'you', 'all', 'hate', 'I', 'alan', 'sandoval', 'alansandoval', 'december', 'who', 'use', 'the', 'word', 'hater', 'in', 'a', 'new', 'year', 'wish', 'marlene', 'marlene', 'december', 'you', 'can', 't', 'just', 'say', 'happy', 'new', 'year', 'koren', 'pollitt', 'korencarpenter', 'december', 'here', 's', 'trump', 's', 'new', 'year', 's', 'eve', 'tweet', 'from', 'happy', 'new', 'year', 'to', 'all', 'include', 'to', 'my', 'many', 'enemy', 'and', 'those', 'who', 'have', 'fight', 'I', 'and', 'lose', 'so', 'badly', 'they', 'just', 'don', 't', 'know', 'what', 'to', 'do', 'love', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'this', 'be', 'nothing', 'new', 'for', 'trump', 'he', 's', 'be', 'do', 'this', 'for', 'year', 'trump', 'have', 'direct', 'message', 'to', 'his', 'enemy', 'and', 'hater', 'for', 'new', 'year', 's', 'easter', 'thanksgiving', 'and', 'the', 'anniversary', 'of', 'pic', 'twitter', 'com', 'fpae', 'kypa', 'daniel', 'dale', 'ddale', 'december', 'trump', 's', 'holiday', 'tweet', 'be', 'clearly', 'not', 'presidential', 'how', 'long', 'do', 'he', 'work', 'at', 'hallmark', 'before', 'become', 'president', 'steven', 'goodine', 'sgoodine', 'december', 'he', 's', 'always', 'be', 'like', 'this', 'the', 'only', 'difference', 'be', 'that', 'in', 'the', 'last', 'few', 'year', 'his', 'filter', 'have', 'be', 'break', 'down', 'roy', 'schulze', 'thbthttt', 'december', 'who', 'apart', 'from', 'a', 'teenager', 'use', 'the', 'term', 'hater', 'wendy', 'wendywhistle', 'december', 'he', 's', 'a', 'fucking', 'year', 'old', 'who', 'know', 'rainyday', 'december', 'so', 'to', 'all', 'the', 'people', 'who', 'vote', 'for', 'this', 'a', 'hole', 'thinking', 'he', 'would', 'change', 'once', 'he', 'get', 'into', 'power', 'you', 'be', 'wrong', 'year', 'old', 'man', 'don', 't', 'change', 'and', 'now', 'he', 's', 'a', 'year', 'old', 'photo', 'by', 'andrew', 'burton', 'getty', 'image']\n",
      " \n",
      "Remove stopword & punctuation: \n",
      "['donald', 'trump', 'wish', 'americans', 'happy', 'new', 'year', 'leave', 'instead', 'give', 'shout', 'enemy', 'hater', 'dishonest', 'fake', 'news', 'medium', 'former', 'reality', 'show', 'star', 'one', 'job', 'country', 'rapidly', 'grow', 'strong', 'smart', 'I', 'want', 'wish', 'friend', 'supporter', 'enemy', 'hater', 'even', 'dishonest', 'fake', 'news', 'medium', 'happy', 'healthy', 'new', 'year', 'president', 'angry', 'pant', 'tweet', 'great', 'year', 'america', 'country', 'rapidly', 'grow', 'strong', 'smart', 'I', 'want', 'wish', 'friend', 'supporter', 'enemy', 'hater', 'even', 'dishonest', 'fake', 'news', 'medium', 'happy', 'healthy', 'new', 'year', 'great', 'year', 'america', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'trump', 'tweet', 'go', 'welll', 'expect', 'kind', 'president', 'send', 'new', 'year', 'greeting', 'like', 'despicable', 'petty', 'infantile', 'gibberish', 'trump', 'lack', 'decency', 'win', 'even', 'allow', 'rise', 'gutter', 'long', 'enough', 'wish', 'american', 'citizen', 'happy', 'new', 'year', 'bishop', 'talbert', 'swan', 'talbertswan', 'december', 'one', 'like', 'calvin', 'calvinstowell', 'december', 'impeachment', 'would', 'make', 'great', 'year', 'america', 'I', 'also', 'accept', 'regain', 'control', 'congress', 'miranda', 'yaver', 'mirandayaver', 'december', 'hear', 'talk', 'include', 'many', 'people', 'hate', 'wonder', 'hate', 'I', 'alan', 'sandoval', 'alansandoval', 'december', 'use', 'word', 'hater', 'new', 'year', 'wish', 'marlene', 'marlene', 'december', 'say', 'happy', 'new', 'year', 'koren', 'pollitt', 'korencarpenter', 'december', 'trump', 'new', 'year', 'eve', 'tweet', 'happy', 'new', 'year', 'include', 'many', 'enemy', 'fight', 'I', 'lose', 'badly', 'know', 'love', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'nothing', 'new', 'trump', 'year', 'trump', 'direct', 'message', 'enemy', 'hater', 'new', 'year', 'easter', 'thanksgiving', 'anniversary', 'pic', 'twitter', 'com', 'fpae', 'kypa', 'daniel', 'dale', 'ddale', 'december', 'trump', 'holiday', 'tweet', 'clearly', 'presidential', 'long', 'work', 'hallmark', 'become', 'president', 'steven', 'goodine', 'sgoodine', 'december', 'always', 'like', 'difference', 'last', 'year', 'filter', 'break', 'roy', 'schulze', 'thbthttt', 'december', 'apart', 'teenager', 'use', 'term', 'hater', 'wendy', 'wendywhistle', 'december', 'fucking', 'year', 'old', 'know', 'rainyday', 'december', 'people', 'vote', 'hole', 'thinking', 'would', 'change', 'get', 'power', 'wrong', 'year', 'old', 'man', 'change', 'year', 'old', 'photo', 'andrew', 'burton', 'getty', 'image']\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\",'no','nor','not'])\n",
    "\n",
    "def spacy_process(text):\n",
    "    print(text)\n",
    "    print(100*'*')\n",
    "    text = clean_text(text)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #Tokenization and lemmatization are done with the spacy nlp pipeline commands\n",
    "    lemma_list = []\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    print(\"Tokenize+Lemmatize:\")\n",
    "    print(lemma_list)\n",
    "    \n",
    "    #Filter the stopword\n",
    "    filtered_sentence =[] \n",
    "    for word in lemma_list:\n",
    "        if word not in custom_stopwords:\n",
    "            filtered_sentence.append(word)\n",
    "    \n",
    "    #Remove punctuation\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in filtered_sentence:\n",
    "        if word in punctuations:\n",
    "            filtered_sentence.remove(word)\n",
    "    print(\" \")\n",
    "    print(\"Remove stopword & punctuation: \")\n",
    "    print(filtered_sentence)\n",
    "\n",
    "first_row = fake_df.iloc[0]\n",
    "spacy_process(first_row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edaef9d03e0964944a4ac8a8046f0ca7775b12f92df181532561f3229a0e765e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
