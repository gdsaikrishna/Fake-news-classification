{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T05:32:41.350021Z","iopub.execute_input":"2022-03-28T05:32:41.350346Z","iopub.status.idle":"2022-03-28T05:32:41.377024Z","shell.execute_reply.started":"2022-03-28T05:32:41.350266Z","shell.execute_reply":"2022-03-28T05:32:41.376156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install keras","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:41.378265Z","iopub.execute_input":"2022-03-28T05:32:41.378994Z","iopub.status.idle":"2022-03-28T05:32:41.382753Z","shell.execute_reply.started":"2022-03-28T05:32:41.378945Z","shell.execute_reply":"2022-03-28T05:32:41.381893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom PIL import Image, ImageChops, ImageEnhance\nimport os\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:41.384157Z","iopub.execute_input":"2022-03-28T05:32:41.384616Z","iopub.status.idle":"2022-03-28T05:32:47.808483Z","shell.execute_reply.started":"2022-03-28T05:32:41.384585Z","shell.execute_reply":"2022-03-28T05:32:47.807514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    \n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n    \n    ela_image = ImageChops.difference(image, temp_image)\n    \n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n    \n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:47.810555Z","iopub.execute_input":"2022-03-28T05:32:47.810829Z","iopub.status.idle":"2022-03-28T05:32:47.817735Z","shell.execute_reply.started":"2022-03-28T05:32:47.8108Z","shell.execute_reply":"2022-03-28T05:32:47.816843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00003.jpg'\nImage.open(real_image_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:47.818866Z","iopub.execute_input":"2022-03-28T05:32:47.81917Z","iopub.status.idle":"2022-03-28T05:32:47.929603Z","shell.execute_reply.started":"2022-03-28T05:32:47.819133Z","shell.execute_reply":"2022-03-28T05:32:47.928941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(real_image_path, 90)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:47.930662Z","iopub.execute_input":"2022-03-28T05:32:47.931411Z","iopub.status.idle":"2022-03-28T05:32:47.96033Z","shell.execute_reply.started":"2022-03-28T05:32:47.931376Z","shell.execute_reply":"2022-03-28T05:32:47.959368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nfake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_CNN_M_N_cha00026_cha00028_11784.jpg'\nImage.open(fake_image_path)\n#../input/casia-dataset/CASIA2/Tp/Tp_D_CNN_M_N_cha00026_cha00028_11784.jpg","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:47.961696Z","iopub.execute_input":"2022-03-28T05:32:47.962036Z","iopub.status.idle":"2022-03-28T05:32:48.02878Z","shell.execute_reply.started":"2022-03-28T05:32:47.961996Z","shell.execute_reply":"2022-03-28T05:32:48.027874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(fake_image_path, 90)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:48.029895Z","iopub.execute_input":"2022-03-28T05:32:48.030439Z","iopub.status.idle":"2022-03-28T05:32:48.112353Z","shell.execute_reply.started":"2022-03-28T05:32:48.030406Z","shell.execute_reply":"2022-03-28T05:32:48.111577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (128, 128)\ndef prepare_image(image_path):\n    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:48.113291Z","iopub.execute_input":"2022-03-28T05:32:48.11423Z","iopub.status.idle":"2022-03-28T05:32:48.119761Z","shell.execute_reply.started":"2022-03-28T05:32:48.114185Z","shell.execute_reply":"2022-03-28T05:32:48.118819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [] # ELA converted images\nY = []\n\nimport random\npath = '/kaggle/input/casia-dataset/CASIA2/Au/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(1)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nrandom.shuffle(X)\nX = X[:2500]\nY = Y[:2500]\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:32:48.122659Z","iopub.execute_input":"2022-03-28T05:32:48.123291Z","iopub.status.idle":"2022-03-28T05:35:33.477049Z","shell.execute_reply.started":"2022-03-28T05:32:48.123252Z","shell.execute_reply":"2022-03-28T05:35:33.475954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/casia-dataset/CASIA2/Tp/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))\n            Y.append(0)\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\nprint(len(X), len(Y))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:35:33.4784Z","iopub.execute_input":"2022-03-28T05:35:33.479127Z","iopub.status.idle":"2022-03-28T05:36:33.04236Z","shell.execute_reply.started":"2022-03-28T05:35:33.479078Z","shell.execute_reply":"2022-03-28T05:36:33.041415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\nY = to_categorical(Y, 2)\nX = X.reshape(-1, 128, 128, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:36:33.043768Z","iopub.execute_input":"2022-03-28T05:36:33.044079Z","iopub.status.idle":"2022-03-28T05:36:33.772538Z","shell.execute_reply.started":"2022-03-28T05:36:33.044039Z","shell.execute_reply":"2022-03-28T05:36:33.7717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\nX = X.reshape(-1,1,1,1)\nprint(len(X_train), len(Y_train))\nprint(len(X_val), len(Y_val))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:36:33.774081Z","iopub.execute_input":"2022-03-28T05:36:33.774407Z","iopub.status.idle":"2022-03-28T05:36:34.426835Z","shell.execute_reply.started":"2022-03-28T05:36:33.774368Z","shell.execute_reply":"2022-03-28T05:36:34.425988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = 'softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:58:42.858696Z","iopub.execute_input":"2022-03-28T05:58:42.859743Z","iopub.status.idle":"2022-03-28T05:58:42.868031Z","shell.execute_reply.started":"2022-03-28T05:58:42.859669Z","shell.execute_reply":"2022-03-28T05:58:42.867187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:58:42.879367Z","iopub.execute_input":"2022-03-28T05:58:42.879838Z","iopub.status.idle":"2022-03-28T05:58:43.003191Z","shell.execute_reply.started":"2022-03-28T05:58:42.879801Z","shell.execute_reply":"2022-03-28T05:58:43.002202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and init the TPU\nimport tensorflow as tf\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = build_model()\n    epochs = 15\n    batch_size = 32\n    init_lr = 1e-4\n    optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\nearly_stopping = EarlyStopping(monitor = 'val_acc',\n                                  min_delta = 0,\n                                  patience = 2,\n                                  verbose = 0,\n                                  mode = 'auto')\nhist = model.fit(X_train,\n                     Y_train,\n                     batch_size = batch_size,\n                     epochs = epochs,\n                    validation_data = (X_val, Y_val),\n                    callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-03-28T05:58:43.005019Z","iopub.execute_input":"2022-03-28T05:58:43.00528Z","iopub.status.idle":"2022-03-28T06:00:15.467101Z","shell.execute_reply.started":"2022-03-28T05:58:43.005248Z","shell.execute_reply":"2022-03-28T06:00:15.46611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:00:15.468511Z","iopub.execute_input":"2022-03-28T06:00:15.468785Z","iopub.status.idle":"2022-03-28T06:00:15.859651Z","shell.execute_reply.started":"2022-03-28T06:00:15.468748Z","shell.execute_reply":"2022-03-28T06:00:15.858761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:00:15.860896Z","iopub.execute_input":"2022-03-28T06:00:15.86122Z","iopub.status.idle":"2022-03-28T06:00:15.871386Z","shell.execute_reply.started":"2022-03-28T06:00:15.86119Z","shell.execute_reply":"2022-03-28T06:00:15.870347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:00:15.873569Z","iopub.execute_input":"2022-03-28T06:00:15.873934Z","iopub.status.idle":"2022-03-28T06:00:26.403181Z","shell.execute_reply.started":"2022-03-28T06:00:15.873891Z","shell.execute_reply":"2022-03-28T06:00:26.402225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfake_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in tqdm(fake_image):\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\n            #Confidence: {np.amax(y_pred) * 100:0.2f}\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:00:26.404785Z","iopub.execute_input":"2022-03-28T06:00:26.405124Z","iopub.status.idle":"2022-03-28T06:15:21.923394Z","shell.execute_reply.started":"2022-03-28T06:00:26.405081Z","shell.execute_reply":"2022-03-28T06:15:21.922548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Au/')\ncorrect_r = 0\ntotal_r = 0\nfor file_name in tqdm(real_image):\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        real_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Au/', file_name)\n        image = prepare_image(real_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total_r += 1\n        if y_pred_class == 1:\n            correct_r += 1\n        if total_r == 3000:\n            break\nprint(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:15:21.924631Z","iopub.execute_input":"2022-03-28T06:15:21.924911Z","iopub.status.idle":"2022-03-28T06:36:36.17281Z","shell.execute_reply.started":"2022-03-28T06:15:21.92488Z","shell.execute_reply":"2022-03-28T06:36:36.170072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct += correct_r\ntotal += total_r\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:36:36.174072Z","iopub.execute_input":"2022-03-28T06:36:36.175349Z","iopub.status.idle":"2022-03-28T06:36:36.181208Z","shell.execute_reply.started":"2022-03-28T06:36:36.175314Z","shell.execute_reply":"2022-03-28T06:36:36.180231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\ndef vgg_model():\n    vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n\n    model = Sequential()\n    #Note\n    for layer in vgg_conv.layers[:-5]:\n        layer.trainable = False\n\n    for layer in vgg_conv.layers:\n        print(layer, layer.trainable)\n\n    model.add(vgg_conv)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n    return model\n\nnew_model = vgg_model()\nnew_model.summary","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:36:36.182501Z","iopub.execute_input":"2022-03-28T06:36:36.182785Z","iopub.status.idle":"2022-03-28T06:36:37.409956Z","shell.execute_reply.started":"2022-03-28T06:36:36.182753Z","shell.execute_reply":"2022-03-28T06:36:37.409122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\n\nwith tpu_strategy.scope():\n    new_model = vgg_model()\n    epochs = 15\n    batch_size = 32\n    init_lr = 1e-4\n    optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n    new_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\nhist = new_model.fit(X_train,\n                     Y_train,\n                     batch_size = batch_size,\n                     epochs = epochs,\n                    validation_data = (X_val, Y_val))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:36:37.411032Z","iopub.execute_input":"2022-03-28T06:36:37.411532Z","iopub.status.idle":"2022-03-28T06:37:55.879395Z","shell.execute_reply.started":"2022-03-28T06:36:37.411482Z","shell.execute_reply":"2022-03-28T06:37:55.878481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:37:55.880829Z","iopub.execute_input":"2022-03-28T06:37:55.881077Z","iopub.status.idle":"2022-03-28T06:37:56.286321Z","shell.execute_reply.started":"2022-03-28T06:37:55.881048Z","shell.execute_reply":"2022-03-28T06:37:56.285474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:37:56.287631Z","iopub.execute_input":"2022-03-28T06:37:56.288085Z","iopub.status.idle":"2022-03-28T06:37:57.78984Z","shell.execute_reply.started":"2022-03-28T06:37:56.288055Z","shell.execute_reply":"2022-03-28T06:37:57.788923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfake_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Tp/')\ncorrect = 0\ntotal = 0\nfor file_name in tqdm(fake_image):\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        fake_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Tp/', file_name)\n        image = prepare_image(fake_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = new_model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total += 1\n        if y_pred_class == 0:\n            correct += 1\nprint(f'Total: {total}, Correct: {correct}, Acc: {correct / total * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:37:57.791251Z","iopub.execute_input":"2022-03-28T06:37:57.791554Z","iopub.status.idle":"2022-03-28T06:52:34.074528Z","shell.execute_reply.started":"2022-03-28T06:37:57.791513Z","shell.execute_reply":"2022-03-28T06:52:34.073726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_image = os.listdir('/kaggle/input/casia-dataset/casia/CASIA2/Au/')\ncorrect_r = 0\ntotal_r = 0\nfor file_name in tqdm(real_image):\n    if file_name.endswith('jpg') or filename.endswith('png'):\n        real_image_path = os.path.join('/kaggle/input/casia-dataset/casia/CASIA2/Au/', file_name)\n        image = prepare_image(real_image_path)\n        image = image.reshape(-1, 128, 128, 3)\n        y_pred = new_model.predict(image)\n        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n        total_r += 1\n        if y_pred_class == 1:\n            correct_r += 1\n        if total_r == 3000:\n            break\nprint(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r / total_r * 100.0}')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T06:52:34.07727Z","iopub.execute_input":"2022-03-28T06:52:34.077516Z","iopub.status.idle":"2022-03-28T07:13:31.757047Z","shell.execute_reply.started":"2022-03-28T06:52:34.077487Z","shell.execute_reply":"2022-03-28T07:13:31.754896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T07:13:31.758451Z","iopub.execute_input":"2022-03-28T07:13:31.759113Z","iopub.status.idle":"2022-03-28T07:13:32.490723Z","shell.execute_reply.started":"2022-03-28T07:13:31.759077Z","shell.execute_reply":"2022-03-28T07:13:32.489823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import model_from_json\nfrom PIL import Image, ImageChops, ImageEnhance\nimport os\nimport numpy as np\nimport pandas as pd\n\njson_file = open('../input/fakeimagemodel/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\n\nloaded_model.load_weights(\"../input/fakeimagemodel/model.h5\")\nprint(\"Loaded model from disk\")\n\ndef convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    \n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n    \n    ela_image = ImageChops.difference(image, temp_image)\n    \n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n    \n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image\n\nimage_size = (128, 128)\ndef prepare_image(image_path):\n    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0\ndef prediction(path):\n    image = prepare_image(path)\n    image = image.reshape(-1, 128, 128, 3)\n    y_pred = loaded_model.predict(image)\n    y_pred_class = np.argmax(y_pred, axis = 1)[0]\n    if y_pred_class == 1:\n        print(\"Not Forged: Real Image\")\n        print(f'Confidence: {np.amax(y_pred) * 100:0.2f}')\n    else:\n        print(\"Forged: Fake Image\")\n        print(f'Confidence: {np.amax(y_pred) * 100:0.2f}')\n\nimage_path = r'../input/casia-dataset/CASIA2/Tp/Tp_D_CNN_M_N_nat10156_ani00024_12016.jpg'\nprint(prediction(image_path))\nImage.open(image_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T07:13:32.491934Z","iopub.execute_input":"2022-03-28T07:13:32.492156Z","iopub.status.idle":"2022-03-28T07:13:34.65452Z","shell.execute_reply.started":"2022-03-28T07:13:32.492131Z","shell.execute_reply":"2022-03-28T07:13:34.653696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_ela_image(image_path, 90)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T07:13:34.655912Z","iopub.execute_input":"2022-03-28T07:13:34.656784Z","iopub.status.idle":"2022-03-28T07:13:34.852477Z","shell.execute_reply.started":"2022-03-28T07:13:34.656734Z","shell.execute_reply":"2022-03-28T07:13:34.851876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lime\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nimport matplotlib.pyplot as plt\nimport random\nexplainer = lime_image.LimeImageExplainer(random_state=42)\n#image = prepare_image(image_path)\nimage = Image.open(image_path).convert('RGB')\nimage = image.reshape(-1, 128, 128, 3)\nexplanation = explainer.explain_instance(image, loaded_model.predict, top_labels=5, hide_color=0, num_samples=1000)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T07:13:34.853502Z","iopub.execute_input":"2022-03-28T07:13:34.854233Z","iopub.status.idle":"2022-03-28T07:13:36.020799Z","shell.execute_reply.started":"2022-03-28T07:13:34.854193Z","shell.execute_reply":"2022-03-28T07:13:36.019789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}